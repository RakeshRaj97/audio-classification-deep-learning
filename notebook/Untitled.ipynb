{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "from PIL import Image\n",
    "import albumentations\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pretrainedmodels\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/fred/oz138/test/data/train.csv\")\n",
    "test = pd.read_csv(\"/fred/oz138/test/data/test.csv\")\n",
    "submission = pd.read_csv(\"/fred/oz138/test/data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "class args:\n",
    "    \n",
    "    ROOT_PATH = \"/fred/oz138/test/data/train_audio\"\n",
    "    \n",
    "    num_classes = 264\n",
    "    max_duration= 5 # seconds\n",
    "    \n",
    "    sample_rate = 32000\n",
    "    \n",
    "    img_height = 128\n",
    "    img_width = 313\n",
    "    \n",
    "    batch_size = 16\n",
    "    num_workers = 4\n",
    "    epochs = 2\n",
    "    \n",
    "    lr = 0.0009\n",
    "    wd = 1e-5\n",
    "    momentum = 0.9\n",
    "    eps = 1e-8\n",
    "    betas = (0.9, 0.999)\n",
    "    \n",
    "    melspectrogram_parameters = {\n",
    "        \"n_mels\": 128,\n",
    "        \"fmin\": 20,\n",
    "        \"fmax\": 16000\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio files\n",
    "def load_audio(path):\n",
    "    try:\n",
    "        sound = AudioSegment.from_wav(path)\n",
    "        sound = sound.set_frame_rate(args.sample_rate)\n",
    "        sound_array = np.array(sound.get_array_of_samples(), dtype=np.float32)\n",
    "    except:\n",
    "        sound_array = np.zeros(args.sample_rate * args.max_duration, dtype=np.float32)\n",
    "        \n",
    "    return sound_array, args.sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
    "\n",
    "class AudioTransform(BasicTransform):\n",
    "    \"\"\"Transform for Audio task\"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "\n",
    "class NoiseInjection(AudioTransform):\n",
    "    \"\"\"It simply add some random value into data by using numpy\"\"\"\n",
    "    def __init__(self, noise_levels=(0, 0.5), always_apply=False, p=0.5):\n",
    "        super(NoiseInjection, self).__init__(always_apply, p)\n",
    "\n",
    "        self.noise_levels = noise_levels\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "        noise_level = np.random.uniform(*self.noise_levels)\n",
    "        noise = np.random.randn(len(sound))\n",
    "        augmented_sound = sound + noise_level * noise\n",
    "        # Cast back to same data type\n",
    "        augmented_sound = augmented_sound.astype(type(sound[0]))\n",
    "\n",
    "        return augmented_sound, sr\n",
    "\n",
    "class ShiftingTime(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ShiftingTime, self).__init__(always_apply, p)\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        shift_max = np.random.randint(1,len(sound))\n",
    "        shift = np.random.randint(int(sr * shift_max))\n",
    "        direction = np.random.randint(0,2)\n",
    "        if direction == 1:\n",
    "            shift = -shift\n",
    "\n",
    "        augmented_sound = np.roll(sound, shift)\n",
    "        # Set to silence for heading/ tailing\n",
    "        if shift > 0:\n",
    "            augmented_sound[:shift] = 0\n",
    "        else:\n",
    "            augmented_sound[shift:] = 0\n",
    "\n",
    "        return augmented_sound, sr\n",
    "\n",
    "class PitchShift(AudioTransform):\n",
    "    \n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(PitchShift, self).__init__(always_apply, p)\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        n_steps = np.random.randint(-10, 10)\n",
    "        augmented_sound = librosa.effects.pitch_shift(sound, sr, n_steps)\n",
    "\n",
    "        return augmented_sound, sr\n",
    "\n",
    "class TimeStretch(AudioTransform):\n",
    "    \n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(TimeStretch, self).__init__(always_apply, p)\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        rate = np.random.uniform(0, 2)\n",
    "        augmented_sound = librosa.effects.time_stretch(sound, rate)\n",
    "\n",
    "        return augmented_sound, sr\n",
    "\n",
    "class RandomAudio(AudioTransform):\n",
    "    \n",
    "    def __init__(self,  seconds=5, always_apply=False, p=0.5):\n",
    "        super(RandomAudio, self).__init__(always_apply, p)\n",
    "\n",
    "        self.seconds = seconds\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        shift = np.random.randint(len(sound))\n",
    "        trim_sound = np.roll(sound, shift)\n",
    "\n",
    "        min_samples = int(sr * self.seconds)\n",
    "\n",
    "        if len(trim_sound) < min_samples:\n",
    "            padding = min_samples - len(trim_sound)\n",
    "            offset = padding // 2\n",
    "            trim_sound = np.pad(trim_sound, (offset, padding - offset), \"constant\")\n",
    "        else:\n",
    "            trim_sound = trim_sound[:min_samples]\n",
    "\n",
    "        return trim_sound, sr\n",
    "\n",
    "class MelSpectrogram(AudioTransform):\n",
    "\n",
    "    def __init__(self, parameters, always_apply=False, p=0.5):\n",
    "        super(MelSpectrogram, self).__init__(always_apply, p)\n",
    "\n",
    "        self.parameters = parameters\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(sound, sr=sr, **self.parameters)\n",
    "        melspec = librosa.power_to_db(melspec)\n",
    "        melspec = melspec.astype(np.float32)\n",
    "\n",
    "        return melspec, sr\n",
    "\n",
    "class SpecAugment(AudioTransform):\n",
    "    \n",
    "    def __init__(self, num_mask=2, freq_masking=0.15, time_masking=0.20, always_apply=False, p=0.5):\n",
    "        super(SpecAugment, self).__init__(always_apply, p)\n",
    "\n",
    "        self.num_mask = num_mask\n",
    "        self.freq_masking = freq_masking\n",
    "        self.time_masking = time_masking\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        melspec, sr = data\n",
    "\n",
    "        spec_aug = self.spec_augment(melspec, \n",
    "                                     self.num_mask,\n",
    "                                     self.freq_masking,\n",
    "                                     self.time_masking,\n",
    "                                     melspec.min())\n",
    "        \n",
    "\n",
    "\n",
    "        return spec_aug, sr\n",
    "    \n",
    "    # Source: https://www.kaggle.com/davids1992/specaugment-quick-implementation\n",
    "    def spec_augment(self, \n",
    "                    spec: np.ndarray,\n",
    "                    num_mask=2,\n",
    "                    freq_masking=0.15,\n",
    "                    time_masking=0.20,\n",
    "                    value=0):\n",
    "        spec = spec.copy()\n",
    "        num_mask = random.randint(1, num_mask)\n",
    "        for i in range(num_mask):\n",
    "            all_freqs_num, all_frames_num  = spec.shape\n",
    "            freq_percentage = random.uniform(0.0, freq_masking)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[f0:f0 + num_freqs_to_mask, :] = value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[:, t0:t0 + num_frames_to_mask] = value\n",
    "\n",
    "        return spec\n",
    "\n",
    "class SpectToImage(AudioTransform):\n",
    "\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(SpectToImage, self).__init__(always_apply, p)\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        image, sr = data\n",
    "        delta = librosa.feature.delta(image)\n",
    "        accelerate = librosa.feature.delta(image, order=2)\n",
    "        image = np.stack([image, delta, accelerate], axis=0)\n",
    "        image = image.astype(np.float32) / 100.0\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example\n",
    "\n",
    "train_audio_augmentation = albumentations.Compose([\n",
    "     RandomAudio(seconds=args.max_duration, always_apply=True),\n",
    "     NoiseInjection(p=0.33),\n",
    "     MelSpectrogram(parameters=args.melspectrogram_parameters,always_apply=True),\n",
    "     SpecAugment(p=0.33),\n",
    "     SpectToImage(always_apply=True)\n",
    "])\n",
    "\n",
    "valid_audio_augmentation = albumentations.Compose([\n",
    "     RandomAudio(seconds=args.max_duration, always_apply=True),\n",
    "     MelSpectrogram(parameters=args.melspectrogram_parameters,always_apply=True),\n",
    "     SpectToImage(always_apply=True)\n",
    "])\n",
    "\n",
    "\n",
    "path = f\"{args.ROOT_PATH}/aldfly/XC135454.mp3\"\n",
    "data = load_audio(path)\n",
    "image = train_audio_augmentation(data=data)['data']\n",
    "\n",
    "plt.imshow(image.transpose(1,2,0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bird",
   "language": "python",
   "name": "bird"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
