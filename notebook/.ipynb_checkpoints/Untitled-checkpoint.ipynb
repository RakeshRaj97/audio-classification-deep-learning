{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "from PIL import Image\n",
    "import albumentations\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pretrainedmodels\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/fred/oz138/test/data/train.csv\")\n",
    "test = pd.read_csv(\"/fred/oz138/test/data/test.csv\")\n",
    "submission = pd.read_csv(\"/fred/oz138/test/data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "class args:\n",
    "    \n",
    "    ROOT_PATH = \"/fred/oz138/test/data/train_audio\"\n",
    "    \n",
    "    num_classes = 264\n",
    "    max_duration= 5 # seconds\n",
    "    \n",
    "    sample_rate = 32000\n",
    "    \n",
    "    img_height = 128\n",
    "    img_width = 313\n",
    "    \n",
    "    batch_size = 16\n",
    "    num_workers = 4\n",
    "    epochs = 2\n",
    "    \n",
    "    lr = 0.0009\n",
    "    wd = 1e-5\n",
    "    momentum = 0.9\n",
    "    eps = 1e-8\n",
    "    betas = (0.9, 0.999)\n",
    "    \n",
    "    melspectrogram_parameters = {\n",
    "        \"n_mels\": 128,\n",
    "        \"fmin\": 20,\n",
    "        \"fmax\": 16000\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio files\n",
    "def load_audio(path):\n",
    "    try:\n",
    "        sound = AudioSegment.from_wav(path)\n",
    "        sound = sound.set_frame_rate(args.sample_rate)\n",
    "        sound_array = np.array(sound.get_array_of_samples(), dtype=np.float32)\n",
    "    except:\n",
    "        sound_array = np.zeros(args.sample_rate * args.max_duration, dtype=np.float32)\n",
    "        \n",
    "    return sound_array, args.sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
    "\n",
    "class AudioTransform(BasicTransform):\n",
    "    \"\"\"Transform for Audio task\"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "\n",
    "class NoiseInjection(AudioTransform):\n",
    "    \"\"\"It simply add some random value into data by using numpy\"\"\"\n",
    "    def __init__(self, noise_levels=(0, 0.5), always_apply=False, p=0.5):\n",
    "        super(NoiseInjection, self).__init__(always_apply, p)\n",
    "\n",
    "        self.noise_levels = noise_levels\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "        noise_level = np.random.uniform(*self.noise_levels)\n",
    "        noise = np.random.randn(len(sound))\n",
    "        augmented_sound = sound + noise_level * noise\n",
    "        # Cast back to same data type\n",
    "        augmented_sound = augmented_sound.astype(type(sound[0]))\n",
    "\n",
    "        return augmented_sound, sr\n",
    "\n",
    "class ShiftingTime(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ShiftingTime, self).__init__(always_apply, p)\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        shift_max = np.random.randint(1,len(sound))\n",
    "        shift = np.random.randint(int(sr * shift_max))\n",
    "        direction = np.random.randint(0,2)\n",
    "        if direction == 1:\n",
    "            shift = -shift\n",
    "\n",
    "        augmented_sound = np.roll(sound, shift)\n",
    "        # Set to silence for heading/ tailing\n",
    "        if shift > 0:\n",
    "            augmented_sound[:shift] = 0\n",
    "        else:\n",
    "            augmented_sound[shift:] = 0\n",
    "\n",
    "        return augmented_sound, sr\n",
    "\n",
    "class PitchShift(AudioTransform):\n",
    "    \n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(PitchShift, self).__init__(always_apply, p)\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        n_steps = np.random.randint(-10, 10)\n",
    "        augmented_sound = librosa.effects.pitch_shift(sound, sr, n_steps)\n",
    "\n",
    "        return augmented_sound, sr\n",
    "\n",
    "class TimeStretch(AudioTransform):\n",
    "    \n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(TimeStretch, self).__init__(always_apply, p)\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        rate = np.random.uniform(0, 2)\n",
    "        augmented_sound = librosa.effects.time_stretch(sound, rate)\n",
    "\n",
    "        return augmented_sound, sr\n",
    "\n",
    "class RandomAudio(AudioTransform):\n",
    "    \n",
    "    def __init__(self,  seconds=5, always_apply=False, p=0.5):\n",
    "        super(RandomAudio, self).__init__(always_apply, p)\n",
    "\n",
    "        self.seconds = seconds\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        shift = np.random.randint(len(sound))\n",
    "        trim_sound = np.roll(sound, shift)\n",
    "\n",
    "        min_samples = int(sr * self.seconds)\n",
    "\n",
    "        if len(trim_sound) < min_samples:\n",
    "            padding = min_samples - len(trim_sound)\n",
    "            offset = padding // 2\n",
    "            trim_sound = np.pad(trim_sound, (offset, padding - offset), \"constant\")\n",
    "        else:\n",
    "            trim_sound = trim_sound[:min_samples]\n",
    "\n",
    "        return trim_sound, sr\n",
    "\n",
    "class MelSpectrogram(AudioTransform):\n",
    "\n",
    "    def __init__(self, parameters, always_apply=False, p=0.5):\n",
    "        super(MelSpectrogram, self).__init__(always_apply, p)\n",
    "\n",
    "        self.parameters = parameters\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(sound, sr=sr, **self.parameters)\n",
    "        melspec = librosa.power_to_db(melspec)\n",
    "        melspec = melspec.astype(np.float32)\n",
    "\n",
    "        return melspec, sr\n",
    "\n",
    "class SpecAugment(AudioTransform):\n",
    "    \n",
    "    def __init__(self, num_mask=2, freq_masking=0.15, time_masking=0.20, always_apply=False, p=0.5):\n",
    "        super(SpecAugment, self).__init__(always_apply, p)\n",
    "\n",
    "        self.num_mask = num_mask\n",
    "        self.freq_masking = freq_masking\n",
    "        self.time_masking = time_masking\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        melspec, sr = data\n",
    "\n",
    "        spec_aug = self.spec_augment(melspec, \n",
    "                                     self.num_mask,\n",
    "                                     self.freq_masking,\n",
    "                                     self.time_masking,\n",
    "                                     melspec.min())\n",
    "        \n",
    "\n",
    "\n",
    "        return spec_aug, sr\n",
    "    \n",
    "    # Source: https://www.kaggle.com/davids1992/specaugment-quick-implementation\n",
    "    def spec_augment(self, \n",
    "                    spec: np.ndarray,\n",
    "                    num_mask=2,\n",
    "                    freq_masking=0.15,\n",
    "                    time_masking=0.20,\n",
    "                    value=0):\n",
    "        spec = spec.copy()\n",
    "        num_mask = random.randint(1, num_mask)\n",
    "        for i in range(num_mask):\n",
    "            all_freqs_num, all_frames_num  = spec.shape\n",
    "            freq_percentage = random.uniform(0.0, freq_masking)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[f0:f0 + num_freqs_to_mask, :] = value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[:, t0:t0 + num_frames_to_mask] = value\n",
    "\n",
    "        return spec\n",
    "\n",
    "class SpectToImage(AudioTransform):\n",
    "\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(SpectToImage, self).__init__(always_apply, p)\n",
    "    \n",
    "    def apply(self, data, **params):\n",
    "        image, sr = data\n",
    "        delta = librosa.feature.delta(image)\n",
    "        accelerate = librosa.feature.delta(image, order=2)\n",
    "        image = np.stack([image, delta, accelerate], axis=0)\n",
    "        image = image.astype(np.float32) / 100.0\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Example\n",
    "\n",
    "train_audio_augmentation = albumentations.Compose([\n",
    "     RandomAudio(seconds=args.max_duration, always_apply=True),\n",
    "     NoiseInjection(p=0.33),\n",
    "     MelSpectrogram(parameters=args.melspectrogram_parameters,always_apply=True),\n",
    "     SpecAugment(p=0.33),\n",
    "     SpectToImage(always_apply=True)\n",
    "])\n",
    "\n",
    "valid_audio_augmentation = albumentations.Compose([\n",
    "     RandomAudio(seconds=args.max_duration, always_apply=True),\n",
    "     MelSpectrogram(parameters=args.melspectrogram_parameters,always_apply=True),\n",
    "     SpectToImage(always_apply=True)\n",
    "])\n",
    "\n",
    "\n",
    "path = f\"{args.ROOT_PATH}/aldfly/XC135454.mp3\"\n",
    "data = load_audio(path)\n",
    "image = train_audio_augmentation(data=data)['data']\n",
    "\n",
    "plt.imshow(image.transpose(1,2,0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bird",
   "language": "python",
   "name": "bird"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
